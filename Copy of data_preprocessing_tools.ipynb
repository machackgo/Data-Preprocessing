{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-oRijAoUwpp2Qlz-Kl3k6hNlodWQyf87","timestamp":1718477337712}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing Tools"]},{"cell_type":"code","source":["# note that the training set like X_train,y_train are the data which we are having in the\n","# form of dataset and on that data we will train our modle\n","# we will apply each class of sklearn on our training data and once it has been trained\n","# testing set like X_test and y_test are the new data  which is not in our data set on which we\n","# will predict our values\n","# if the predicted values[test values] are matching with the real test values then our modle is accurate"],"metadata":{"id":"ZxvkiI1L5BGO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"b3Mo9PZTbwLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["# each and every model of ML in there dataset consistes of two types of data\n","# 1.features or independent variable\n","# 2.dependent variable\n","\n","dataset = pd.read_csv('Data.csv')\n","print(dataset)\n","# here x is an features or independent variable[country,age,salary]--> information\n","# and y is an dependent variable[purchase] --> what we have to predect\n","\n","# features or independent variable = fratures is bascially is information about a person in a dataset\n","# information like where he or she lives what's there are what's there salary\n","# based on that information[features] we will predect whether he will purchase or do some thing which is\n","# known as dependent variable\n","# in each and every data set first few columns will be features and last column will be dependent variable\n","# we will se features or independent variable or dependent variable  through columns wise\n","\n","# if you want to access the range of columns and range of rows simultaneously then\n","\n","X = dataset.iloc[:, :-1].values\n","# if you want to select all the rows from your data set then you can apple dataset.iloc[:]\n","# dataset is our dataset name then iloc is used to select the indexes of the rows then we are not giving a\n","# starting value nor ending value in the range iloc[:] by that it will select all the rows from that dataset\n","\n","# then if you want to select the columns for that selected all rows what we can do is dataset.iloc[:,;]\n","# just by putting comma[,] we are telling that now its time for columns selection for that rows we have\n","# previously selected.\n","y = dataset.iloc[:, -1].values\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90Hg0AO3dC9B","executionInfo":{"status":"ok","timestamp":1720349626370,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"b42eba0c-0fbd-45c6-9dee-4d547fb22119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   Country   Age   Salary Purchased\n","0   France  44.0  72000.0        No\n","1    Spain  27.0  48000.0       Yes\n","2  Germany  30.0  54000.0        No\n","3    Spain  38.0  61000.0        No\n","4  Germany  40.0      NaN       Yes\n","5   France  35.0  58000.0       Yes\n","6    Spain   NaN  52000.0        No\n","7   France  48.0  79000.0       Yes\n","8  Germany  50.0  83000.0        No\n","9   France  37.0  67000.0       Yes\n"]}]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdZj9Tp0tHos","executionInfo":{"status":"ok","timestamp":1720349626370,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"ce66a48d-4c1d-4886-e922-8d58e20cb6c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MjBHIcWltJhD","executionInfo":{"status":"ok","timestamp":1720349626370,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"34ce9abb-5b24-4431-b332-2e35193dffd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"code","source":["# in this block of code we are trying to replace all the missng values[nan] from\n","# the dataset\n","\n","# eg:if we want to replace the nan value from the (salary) column then the strategy we are\n","# applying is we are taking average of the column and replacing it with the missing value\n","# to do that we are using  one of the library of sklearn which is  SimpleImputer\n","\n","from sklearn.impute import SimpleImputer\n","imputer  = SimpleImputer(missing_values=np.nan, strategy='mean')\n","\n","# we are taking 'missing_values' attribute from SimpleImputer in order to select the nan value in first parameter\n","# and in the second parameter we are just generating mean/ average value for that column by using 'strategy' attribute\n","# as second parameter\n","\n","# so up until now we have just selected nan value and generted mean values but this our logic has not been linked with\n","# our dataset in order to link our this logic with the dataset we are using 'fit' method\n","\n","# after the logic have been linked with dataset we have to replace the nan terms with the logic we have genterated\n","#because up until now we have just generated mean values but not replace so it to replace nan with mean value we will use\n","# 'transform' method\n","\n","# 'fit' will take only the columns which consistes of only numerical values so be care full with that do not apply\n","# the 'fit' method which consistes of an string column\n","\n","imputer.fit(X[:,1:3])\n","# specifying the range of the columns which we want to selecet under 'fit' and transform\n","X[:,1:3] = imputer.transform(X[:,1:3])\n","# now this transform will give you a return value and ask which column do you want to replace so thats why we are\n","# taking column index value x[:,1:3] as a variable name to transform function\n","# so now our dataset is changing to store that new dataset we are giving x[:,1:3]="],"metadata":{"id":"OOHgeO0Z4W-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qKsNEDg7L8-L","executionInfo":{"status":"ok","timestamp":1720349629223,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"2e300051-931c-40c6-a4af-3031547902cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"code","source":["# So up until now our data set consistes of Country   Age   Salary Purchased column\n","# where we have split our data set into 2 categories 1.features or independent variable\n","# 2.dependent variables after that we have removed all nan values from our data set\n","# Encoding categorical data:\n","# so in our dataset there we are having two types of datatypes str and int\n","# column Country and Purchases consistes of str datatype but a machine learning can only\n","# take the data which is in the form of int .so we are converting str to int(0 and 1)in this\n","# Encoding categorical data for that we are using sklearn library\n","\n","# STEP :1\n","# we are going to replace country column elements str[france, spain,germany] with int(0 and 1) which is called as\n","# OneHotEncoding method\n","# STEP:2\n","# column Purchased str[yes,no] also contain str values which mean we have to replace then also by int(0 and 1) by\n","# using OneHotEncoding\n","\n","# Machine Learning will take only the int values(0,1,2,3,4,5,6,7,8,9) but not str values thats why we are using\n","# OneHotEncoding method which can transform str to int(0 and 1) values binay values"],"metadata":{"id":"JpGbzozi-nyZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer # this is used to  just transform str to int values\n","from sklearn.preprocessing import OneHotEncoder # this is used to replace that transformed int values with str values\n","\n","ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder='passthrough')\n","#                                         1    |      2        | 3   |            4\n","# ColumnTransformer is a class\n","# transformers is an attribute which takes 3 input values\n","# 1.what kind of transformation you want to do --> ['encoder']\n","# 2.by which method/class do you want to that -->[OneHotEncoder()]which convert(srt to int)\n","# 3.name/number of the index values you want to transform\n","# 4.remainder is an attribute which ask which columns do you does not want to apply transformers\n","# x = ct.fit_transform(x)\n","# so now our dataset is changing to store that new dataset we are giving x=\n","# because x is what we are changing\n","# fit_transform will return the output in the form of numpy array so it is crucial to have our 'x' also as an np.array\n","X = np.array(ct.fit_transform(X))\n","# fit_transform is bascially used to combine our logic with the dataset"],"metadata":{"id":"QhV3M0zB6dbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)\n","# how many different names[[3]=france,spain,Germany] are there in a country column  that many column it will make\n","# france = 100, spain = 001, germany = 010"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmaG-mLLHcWA","executionInfo":{"status":"ok","timestamp":1720349629223,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"f94cedb3-b0ec-4f06-bd49-573d5857757e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","source":["# so in the dependent variable[Purchased] we are having the data in the form of the str\n","# now first we have to convert that str to int but if we look closer our dependent variable[Purchased]\n","# is in the form of binary verctor mean we are having only two outcomes [yes or no] so this mean\n","# we have to apply LabelEncoder which convert binary outcome str values[yes or no] to [0 and 1]\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y = le.fit_transform(y)"],"metadata":{"id":"_AvWxljXLSwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sOH5HBsaJE3","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":9,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"9135ac0e-f125-4787-ff46-8a65f7f8d116"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["# the point is when ever we are trainig the model its X_train value will be connected\n","# with y_train values and X_test value will be connected with y_test vaues\n","# so if we want to predict the training values we can just give regressor.predict(X_train)\n","# and that X_train will take all the training values from X_train and y_train in the form of 2D array\n","# same for X_test but if we just give regressor.predict(y_train) that y_train will only take the Training\n","# values from y which is 1D array\n","\n","# so the basic idea is if you want to predict the Training data just give regressor.predict(X_train)\n","# and if you want to predict the test data just give this regressor.predict(X_test)\n","\n","# and we can only compare real training data with predicted Training data\n","# and we can only compare real test data with predicted test data\n","\n","# we could not compare real trainig data with predicted test data because its dimensions will be diffrent"],"metadata":{"id":"sOmEb5GPj6EV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# so now we are splitting our dataset into 2 categories\n","# 1.Training set\n","# 2.Test set\n","# to do that we are using sklearn.model_selection import train_test_split\n","# by this we have to split our dataset into 4 categories x_train,x_test,y_train,y_test\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2,random_state = 1)\n","# lets imagine our dataset consistes of 1 unit so 0.2 unit will go under test_size and\n","# 0.8 will go under training_size\n","# which mean out of 100% from our dataset we are giving 80% to training our data and 20%\n","# to test our data\n","# after splitting our dataset will we randomly split among training set and test set well to make\n","# sure we have same random factors we are using 'random_state = 1'"],"metadata":{"id":"x-sVd8Uu0Lg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(X_train)\n","print(X_test)\n","# print(y_train)\n","print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9pN4xUBkCEE","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"28d84dd7-8ea6-440f-fa81-5e92c241e363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n","[0 1]\n"]}]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9x6ylhSU6qmG","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"6def7041-cd40-4adc-8089-1d07faf3d392"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PT_8rytd6qve","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"1d92303a-bfef-4d4b-f5e0-43d02b71e237"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZXfFHYl6q1f","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"31c67122-cfb8-4ed5-e4e2-f83120cf75af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","source":["print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB9sszyT6q6o","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"1118bc67-75d6-4cf8-a635-6795a561e022"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["**Feature** **Scaling**\n","\n","\n"]},{"cell_type":"code","source":["# why do we use feature scaling:\n","# when you observe [x_test] or [x_train] some values are in 'tens' and some of them are in 'thousand'\n","# which is not good for sacling.\n","# feature scaling will allow you to put your values neareast to each other between [-3 to 3] or [0 and 1] or [-2 to 2]\n","# it will allow to put all of our features on the same scale\n","# why do we need this because in some ML models some feature can be domenated by\n","# others features in such a way that dominates features are not even considered\n","# by ML model to put them under the equal scaling we use this"],"metadata":{"id":"v6QrpRr403Y8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train[:,3:] = sc.fit_transform(X_train[:,3:])\n","X_test[:,3:] = sc.fit_transform(X_test[:,3:])\n","\n","# in feature scaling we are having two categories 1.Noramlization 2.Standardization\n","# you can find formulas for this both in [ML-A-Z-slids][pg:11] but here we dont have to use the\n","# formulas we just have to write the class name [StandardScaler()] and that's it.\n","# we can use StandardScaler for each and every case in feature sacling but we can only\n","# use normalization for a specific case in feature scaling so thats why we are using StandardScaler here\n","# imp: we should not apply feature scaling on dummy variables [0 and 1]under[Splitting the dataset into\n","# the Training set and Test set].\n","# Standardization = x-mean/standard deviation\n","# transform       |       fit method\n","# by using fit method we will apply this formula x-mean/standard deviation to x_train\n","# after that we have to transform that formula\n","# so we have to do two different things 1.fit=apply formula 2.transform\n","# but luckely we have a mathos fit_transform() which will do both methods at the same time\n","# we will apply only transform method to test"],"metadata":{"id":"UvhlTdKlHf3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJr6tDA5bKgV","executionInfo":{"status":"ok","timestamp":1720349629224,"user_tz":-330,"elapsed":5,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"de8eeca9-7ee8-4d83-e1f8-03c64eb77a0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjZ0DL8nbKbg","executionInfo":{"status":"ok","timestamp":1720349629225,"user_tz":-330,"elapsed":5,"user":{"displayName":"Mohammed Faraz","userId":"09790691887558301050"}},"outputId":"88cb3b67-5d4a-41c7-beba-07fcbc1be1ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 -1.0 -1.0]\n"," [1.0 0.0 0.0 1.0 1.0]]\n"]}]},{"cell_type":"code","source":["# if you look at the output of x_test and x_train you will notice that the output is in 2D array[[]]\n","# and the class for feature scaling [StandardScaler] only accept the input which are in 2D array\n","# inputs = x_test and x_train .so check each time is what ever input you are giving is in 2D array\n","# or not if not then first change it into 2D array"],"metadata":{"id":"mG2CWujiTKQM"},"execution_count":null,"outputs":[]}]}